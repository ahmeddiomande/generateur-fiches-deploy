import openai
import streamlit as st
import json
import os
import csv
from datetime import datetime
import re
import unicodedata
from google.oauth2 import service_account
from googleapiclient.discovery import build

# ==============================
# Config & Secrets
# ==============================
openai.api_key = st.secrets["openai"]["api_key"]
google_api_key = st.secrets["google"]["google_api_key"]

# Google Sheets
SPREADSHEET_ID = '1wl_OvLv7c8iN8Z40Xutu7CyrN9rTIQeKgpkDJFtyKIU'  # Remplace par ton propre ID
RANGE_NAME = 'Besoins ASI!A1:Z1000'  # Plage de donn√©es dans Google Sheets

# Chemins de stockage local
OUTPUT_DIR = "out_fiches"
INDEX_CSV = "fiches_index.csv"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ==============================
# Auth Google Sheets
# ==============================
credentials = service_account.Credentials.from_service_account_info(
    json.loads(google_api_key)
)
service = build('sheets', 'v4', credentials=credentials)

# ==============================
# Utilitaires
# ==============================
def slugify(value: str) -> str:
    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')
    value = re.sub(r'[^a-zA-Z0-9_-]+', '-', value).strip('-').lower()
    return value or "fiche"

def parse_date_maybe(s: str):
    """Essaie de parser une date avec quelques formats usuels. Retourne datetime ou None."""
    if not s:
        return None
    for fmt in ("%Y-%m-%d", "%d/%m/%Y", "%d-%m-%Y", "%Y/%m/%d", "%d/%m/%Y %H:%M", "%Y-%m-%d %H:%M:%S"):
        try:
            return datetime.strptime(s.strip(), fmt)
        except Exception:
            continue
    # heuristique : si √ßa ressemble √† une date ISO partielle
    try:
        # tente YYYY-MM-DDTHH:MM:SSZ
        return datetime.fromisoformat(s.replace('Z', '').strip())
    except Exception:
        return None

def detect_date_column(headers):
    """Trouve l'index d'une colonne date probable dans les en-t√™tes."""
    if not headers:
        return None
    keys = ['date', 'timestamp', 'cr√©√©', 'ajout', 'creation', 'added', 'updated', 'maj', 'demarrage', 'start']
    hdr_lower = [h.lower() for h in headers]
    for i, h in enumerate(hdr_lower):
        if any(k in h for k in keys):
            return i
    return None

def read_google_sheet_values():
    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()
    values = result.get('values', [])
    return values

def recuperer_donnees_google_sheet_sorted_recent_first():
    """R√©cup√®re la sheet et renvoie (headers, rows tri√©es du plus r√©cent au moins r√©cent)."""
    values = read_google_sheet_values()
    if not values:
        return [], []
    headers = values[0]
    rows = values[1:]

    # D√©tecte une colonne date et trie desc
    date_idx = detect_date_column(headers)
    if date_idx is not None:
        def row_key(r):
            d = r[date_idx] if len(r) > date_idx else ""
            dt = parse_date_maybe(d)
            # Pour les lignes sans date parseable, on renvoie datetime.min pour qu'elles soient en bas
            return dt or datetime.min
        rows.sort(key=row_key, reverse=True)
    else:
        # Fallback : on suppose que les lignes r√©centes sont en bas -> on inverse pour avoir r√©cent -> ancien
        rows = list(reversed(rows))
    return headers, rows

def save_fiche(content: str, meta: dict):
    """Enregistre la fiche en .md et met √† jour l'index CSV."""
    now = datetime.now()
    ts = now.strftime("%Y%m%d_%H%M%S")
    title = meta.get("titre_poste") or "fiche"
    fname = f"{ts}_{slugify(title)}.md"
    fpath = os.path.join(OUTPUT_DIR, fname)
    with open(fpath, "w", encoding="utf-8") as f:
        f.write(content)

    # maj index
    fieldnames = ["filename", "filepath", "titre_poste", "client", "localisation", "statut_mission",
                  "duree_mission", "salaire", "teletravail", "date_demarrage", "competences", "projet",
                  "generated_at"]
    file_exists = os.path.exists(INDEX_CSV)
    with open(INDEX_CSV, "a", newline="", encoding="utf-8") as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        row = {
            "filename": fname,
            "filepath": fpath,
            "titre_poste": meta.get("titre_poste", ""),
            "client": meta.get("client", ""),
            "localisation": meta.get("localisation", ""),
            "statut_mission": meta.get("statut_mission", ""),
            "duree_mission": meta.get("duree_mission", ""),
            "salaire": meta.get("salaire", ""),
            "teletravail": meta.get("teletravail", ""),
            "date_demarrage": meta.get("date_demarrage", ""),
            "competences": meta.get("competences", ""),
            "projet": meta.get("projet", ""),
            "generated_at": now.isoformat(timespec="seconds"),
        }
        writer.writerow(row)
    return fpath, fname

def load_index_rows():
    if not os.path.exists(INDEX_CSV):
        return []
    rows = []
    with open(INDEX_CSV, "r", encoding="utf-8") as csvfile:
        reader = csv.DictReader(csvfile)
        for r in reader:
            rows.append(r)
    # tri par d√©faut: plus r√©cent -> moins r√©cent
    rows.sort(key=lambda r: r.get("generated_at", ""), reverse=True)
    return rows

def openai_generate_fiche(prompt_text: str):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # Ou gpt-4 si dispos
        messages=[
            {"role": "system", "content": "Vous √™tes un assistant g√©n√©rateur de fiches de poste."},
            {"role": "user", "content": prompt_text}
        ],
        max_tokens=500
    )
    return response['choices'][0]['message']['content'].strip()

def build_prompt_from_row(row):
    # S√©curise les acc√®s aux colonnes comme dans ton code d'origine
    titre_poste   = row[5]  if len(row) > 5  else 'Titre non sp√©cifi√©'
    duree_mission = row[13] if len(row) > 13 else '6 mois'
    statut_mission= row[6]  if len(row) > 6  else ''
    salaire       = row[14] if len(row) > 14 else ''
    teletravail   = row[18] if len(row) > 18 else ''
    date_demarrage= row[12] if len(row) > 12 else ''
    competences   = row[17] if len(row) > 17 else ''
    projet        = row[15] if len(row) > 15 else ''
    client        = row[9]  if len(row) > 9  else ''
    localisation  = row[10] if len(row) > 10 else ''

    prompt_fiche = "Description du poste :\n"
    prompt_fiche += f"- Titre du poste recherch√© : {titre_poste}\n"
    prompt_fiche += f"- Dur√©e de la mission : {duree_mission}\n"
    prompt_fiche += f"- Statut mission : {statut_mission}\n" if statut_mission else ""
    prompt_fiche += f"- Projet : {projet}\n" if projet else ""
    prompt_fiche += f"- Comp√©tences : {competences}\n" if competences else ""
    prompt_fiche += f"- Salaire : {salaire}\n" if salaire else ""
    prompt_fiche += f"- T√©l√©travail : {teletravail}\n" if teletravail else ""
    prompt_fiche += f"- Date de d√©marrage : {date_demarrage}\n" if date_demarrage else ""
    prompt_fiche += f"- Localisation : {localisation}\n" if localisation else ""

    meta = {
        "titre_poste": titre_poste,
        "duree_mission": duree_mission,
        "statut_mission": statut_mission,
        "salaire": salaire,
        "teletravail": teletravail,
        "date_demarrage": date_demarrage,
        "competences": competences,
        "projet": projet,
        "client": client,
        "localisation": localisation
    }
    return prompt_fiche, meta

def generate_from_rpo_pipeline():
    headers, rows = recuperer_donnees_google_sheet_sorted_recent_first()
    if not rows:
        st.warning("Aucune donn√©e trouv√©e dans la Google Sheet.")
        return

    with st.spinner("G√©n√©ration des fiches √† partir du RPO (ordre : r√©cent ‚Üí ancien) ..."):
        for row in rows:
            prompt_fiche, meta = build_prompt_from_row(row)
            try:
                content = openai_generate_fiche(prompt_fiche)
                # Affichage imm√©diat
                st.subheader(f'Fiche de Poste pour {meta["titre_poste"]}:')
                st.write(content)
                # Sauvegarde + index
                path, name = save_fiche(content, meta)
                st.success(f"Fiche enregistr√©e : {name}")
            except Exception as e:
                st.error(f"Erreur g√©n√©ration/sauvegarde pour {meta.get('titre_poste', 'N/A')} : {e}")

# ==============================
# UI
# ==============================
st.title('üéØ IDEALMATCH JOB CREATOR')

tab_accueil, tab_prompt, tab_rpo, tab_fiches = st.tabs(
    ["üè† Accueil", "‚úçÔ∏è G√©n√©ration par prompt", "üìÑ G√©n√©rer avec RPO", "üìö Fiches g√©n√©r√©es"]
)

# -------- Onglet Accueil --------
with tab_accueil:
    st.markdown("""
Bienvenue dans l'outil **IDEALMATCH JOB CREATOR** !  
Cet outil vous permet de g√©n√©rer des fiches de poste personnalis√©es √† l'aide de l'intelligence artificielle (ChatGPT).

### Instructions :
- Onglet **G√©n√©ration par prompt** : √©crivez un prompt libre.
- Onglet **G√©n√©rer avec RPO** : g√©n√©rez √† partir de la Google Sheet.
- Onglet **Fiches g√©n√©r√©es** : retrouvez toutes vos fiches (recherche + t√©l√©chargement).

üìù **Astuces** :
- Soyez pr√©cis dans votre description pour obtenir les meilleurs r√©sultats.
- L'outil utilise la derni√®re version de GPT-3.5 pour vous fournir des r√©sultats de qualit√©.
""")

    if st.button('G√©n√©rer avec RPO (r√©cent ‚Üí ancien)'):
        try:
            generate_from_rpo_pipeline()
        except Exception as e:
            st.error(f"Erreur lors de la r√©cup√©ration ou du traitement des donn√©es : {e}")

# -------- Onglet G√©n√©ration par prompt --------
with tab_prompt:
    user_prompt = st.text_area(
        "√âcrivez ici votre prompt pour g√©n√©rer une fiche de poste :",
        "Entrez ici le prompt pour ChatGPT..."
    )
    if st.button('G√©n√©rer la Fiche de Poste'):
        if user_prompt:
            try:
                content = openai_generate_fiche(user_prompt)
                st.subheader('Fiche de Poste G√©n√©r√©e:')
                st.write(content)

                # m√©tadonn√©es minimales pour l'index si g√©n√©ration par prompt
                meta = {
                    "titre_poste": "Fiche (prompt libre)",
                    "client": "",
                    "localisation": "",
                    "statut_mission": "",
                    "duree_mission": "",
                    "salaire": "",
                    "teletravail": "",
                    "date_demarrage": "",
                    "competences": "",
                    "projet": ""
                }
                path, name = save_fiche(content, meta)
                st.success(f"Fiche enregistr√©e : {name}")
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration de la fiche de poste : {e}")
        else:
            st.warning("Veuillez entrer un prompt avant de soumettre.")

# -------- Onglet G√©n√©rer avec RPO --------
with tab_rpo:
    st.markdown("G√©n√©ration depuis la Google Sheet, **trait√©e du plus r√©cent au moins r√©cent**.")
    if st.button('G√©n√©rer √† partir du fichier RPO (r√©cent ‚Üí ancien)'):
        try:
            generate_from_rpo_pipeline()
        except Exception as e:
            st.error(f"Erreur lors de la r√©cup√©ration ou du traitement des donn√©es : {e}")

# -------- Onglet Fiches g√©n√©r√©es --------
with tab_fiches:
    st.subheader("Toutes les fiches g√©n√©r√©es")
    query = st.text_input("üîé Recherche (titre, client, localisation, comp√©tences, projet, ...)", "")

    rows = load_index_rows()

    # Filtrage plein-texte simple
    if query:
        q = query.lower()
        def match(r):
            hay = " ".join([
                r.get("titre_poste",""), r.get("client",""), r.get("localisation",""),
                r.get("statut_mission",""), r.get("duree_mission",""), r.get("salaire",""),
                r.get("teletravail",""), r.get("date_demarrage",""), r.get("competences",""),
                r.get("projet",""), r.get("filename","")
            ]).lower()
            return q in hay
        rows = list(filter(match, rows))

    if not rows:
        st.info("Aucune fiche enregistr√©e pour le moment.")
    else:
        # Affichage en liste, tri d√©j√† r√©cent -> ancien
        for r in rows:
            with st.container(border=True):
                st.markdown(f"**{r.get('titre_poste','(sans titre)')}** ‚Äî {r.get('localisation','')}  \n"
                            f"Client: {r.get('client','')}  \n"
                            f"üïí G√©n√©r√©e le: {r.get('generated_at','')}")
                file_path = r.get("filepath","")
                if os.path.exists(file_path):
                    with open(file_path, "r", encoding="utf-8") as f:
                        content_preview = f.read()
                    # petit extrait aper√ßu
                    st.text_area("Aper√ßu", content_preview[:1000], height=150, key=f"preview_{r.get('filename','')}")
                    st.download_button("T√©l√©charger", data=content_preview, file_name=r.get("filename","fiche.md"))
                else:
                    st.error("Fichier introuvable sur le disque. V√©rifiez le r√©pertoire de sortie.")
